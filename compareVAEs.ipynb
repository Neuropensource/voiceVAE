{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "import os \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wav = np.load(\"TrainValTest/all_wav.npy\")\n",
    "torch.manual_seed(123)\n",
    "np.random.seed(123)\n",
    "#attention à ce que les données chargées soit bien des données qui n'ait pas été utilisées pour l'entrainement"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Chargement de modèles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from downloader import SpectroDataset\n",
    "from downloader import SpectroDataset4D\n",
    "import models.simpleAE as AE\n",
    "import models.vanillaVAE as VAE\n",
    "import models.modules.bottleneck as BN\n",
    "import models.modules.CNNdecoder as CNNdec\n",
    "import models.modules.CNNencoder as CNNenc\n",
    "import models.VAEcharly as VAEcharly\n",
    "\n",
    "\n",
    "import importlib as implib\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle 1 : AE1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chargement modèle\n",
    "model1 = AE.AE1D(32)\n",
    "state_dic = torch.load(\"modelsParam/AE1D/ep5AE1D.pth\")\n",
    "model1.load_state_dict(state_dic)\n",
    "\n",
    "#chargement données\n",
    "spectros1 = SpectroDataset(test_wav)\n",
    "valid_loader1 = DataLoader(spectros1,batch_size=16,shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle 2 : AE2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chargement modèle\n",
    "model2= AE.AE2D(64)\n",
    "state_dic = torch.load(\"modelsParam/AE2D/ep5AE2D.pth\")\n",
    "model2.load_state_dict(state_dic)\n",
    "\n",
    "#chargement données\n",
    "spectros2 = SpectroDataset4D(test_wav)\n",
    "valid_loader2 = DataLoader(spectros2,batch_size=16,shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle 3 : vanillaVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chargement modèle\n",
    "vencoder = CNNenc.vanillaEncoder(64)\n",
    "vbottleneck = BN.VariationalBottleneck(64)\n",
    "vdecoder = CNNdec.vanillaDecoder(64)\n",
    "model3 = VAE.vanillaVAE(encoder=vencoder,\n",
    "                        bottleneck=vbottleneck,\n",
    "                        reconstructor = vdecoder, \n",
    "                        beta = 1)\n",
    "state_dic = torch.load(\"modelsParam/vanilla/ep5vanillaVAE_cluster.pth\")\n",
    "model3.load_state_dict(state_dic)\n",
    "\n",
    "#chargement données\n",
    "spectros3 = SpectroDataset4D(test_wav)\n",
    "valid_loader3 = DataLoader(spectros3,batch_size=16,shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle 4 : charlyVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chargement modèle\n",
    "encoder = CNNenc.ConvolutionalEncoder(128)\n",
    "bottleneck = BN.VariationalBottleneck(128)\n",
    "decoder = CNNdec.ConvolutionalDecoder(128)\n",
    "model4 = VAEcharly.VAECharly(encoder=encoder, bottleneck=bottleneck, reconstructor=decoder, beta=1)\n",
    "state_dic = torch.load(\"modelsParam/charlyVAE/AE_epoch76.stdc\", map_location=torch.device('cpu'))\n",
    "model4.load_state_dict(state_dic)\n",
    "\n",
    "#chargement données\n",
    "spectros4 = SpectroDataset4D(test_wav)\n",
    "valid_loader4 = DataLoader(spectros4,batch_size=16,shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Comparaisons de modèle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. verification comparabilité des modèles "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### même nombre de paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nombre de paramètres du modèle\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41845\n",
      "979424\n",
      "6175488\n"
     ]
    }
   ],
   "source": [
    "print(count_parameters(model1))\n",
    "print(count_parameters(model2))\n",
    "print(count_parameters(model3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrainement similaire (même nb d'epochs, batch, lr, nb de données, etc...)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualisation des reconstructions et comparaisons 2 à 2 de modèles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1 = next(iter(valid_loader1))\n",
    "batch2 = next(iter(valid_loader2))\n",
    "batch3 = next(iter(valid_loader3))\n",
    "batch4 = next(iter(valid_loader4))\n",
    "\n",
    "recon1 = model1(batch1)\n",
    "recon2 = model2(batch2)\n",
    "recon3 = model3(batch3)\n",
    "recon4 = model4(batch4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 21, 401])\n",
      "torch.Size([16, 1, 401, 21])\n",
      "torch.Size([16, 1, 401, 21])\n",
      "torch.Size([16, 1, 401, 21])\n"
     ]
    }
   ],
   "source": [
    "print(recon1.shape)\n",
    "print(recon2.shape)\n",
    "print(recon3['logits'].shape)\n",
    "print(recon4['logits'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "implib.reload(plt)\n",
    "#affichage des reocnstruction et des spectros originaux \n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "for i in range(3):\n",
    "    print('__________SPECTRO n°',i+1,' :   _______________')\n",
    "    print('Spectro original :')\n",
    "    plt.imshow(np.transpose(batch2[i][0].detach().numpy()))\n",
    "    # on resize pour que les images soient plus grandes\n",
    "\n",
    "    plt.show()\n",
    "    print('Reconstruction 1 :')\n",
    "    plt.imshow(recon1[i].detach().numpy())\n",
    "    plt.show()\n",
    "    print('Reconstruction 2 :')\n",
    "    plt.imshow(np.transpose(recon2[i][0].detach().numpy()))\n",
    "    plt.show()\n",
    "    print('Reconstruction 3 :')\n",
    "    plt.imshow(np.transpose(recon3['logits'][i][0].detach().numpy()))\n",
    "    plt.show()\n",
    "    print('Reconstruction charly :')\n",
    "    plt.imshow(np.transpose(recon4['logits'][i][0].detach().numpy()))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['figure.figsize'] = [20, 5]\n",
    "\n",
    "# fig, axs = plt.subplots(2, 5)\n",
    "\n",
    "# axs[0, 0].imshow(batch2[i][0].detach().numpy())\n",
    "# axs[0, 0].set_title('Spectro original')\n",
    "# axs[0, 1].imshow(np.transpose(recon1[i].detach().numpy()))\n",
    "# axs[0, 1].set_title('Reconstruction 1')\n",
    "# axs[0, 2].imshow((recon2[i][0].detach().numpy()))\n",
    "# axs[0, 2].set_title('Reconstruction 2')\n",
    "# axs[0, 3].imshow(recon3['logits'][i][0].detach().numpy())\n",
    "# axs[0, 3].set_title('Reconstruction 3')\n",
    "# axs[0, 4].imshow(recon4['logits'][i][0].detach().numpy())\n",
    "# axs[0, 4].set_title('Reconstruction charly')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pourquoi le 1D et le 2D se comporte t-il comme ça ? le 1D est beaucoup moins blurry temporellement car il se concentre uniquement sur la reconstruction temporelle, sans se soucier de reconcilier les différentes fréquences ensembles.\n",
    "Et comme le son est avant tout temporel, c'est pas si inintéressant non ?\n",
    "...en faveur d'une architecture qui focalise plus sur la dimension temporel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Etude des espaces latents construits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
